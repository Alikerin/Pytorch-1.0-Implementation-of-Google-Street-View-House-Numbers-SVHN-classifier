{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "###### Import all necessary modules ######\n",
    "##########################################\n",
    "\n",
    "\n",
    "import torch\n",
    "from  torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Define Test Transforms #\n",
    "##########################\n",
    "test_transforms= transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "### Check Cuda Availability ####\n",
    "################################\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "###### Defining Model Class ######\n",
    "##################################\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        hidden1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=48, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(num_features=48),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=1),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        hidden2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=48, out_channels=64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1, padding=1),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        hidden3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=1),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        hidden4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=160, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(num_features=160),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1, padding=1),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        hidden5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=160, out_channels=192, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(num_features=192),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=1),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        hidden6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=192, out_channels=192, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(num_features=192),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1, padding=1),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        hidden7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=192, out_channels=192, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(num_features=192),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=1),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        hidden8 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=192, out_channels=192, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(num_features=192),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1, padding=1),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        hidden9 = nn.Sequential(\n",
    "            nn.Linear(192 * 7 * 7, 3072),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        hidden10 = nn.Sequential(\n",
    "            nn.Linear(3072, 3072),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self._features = nn.Sequential(\n",
    "            hidden1,\n",
    "            hidden2,\n",
    "            hidden3,\n",
    "            hidden4,\n",
    "            hidden5,\n",
    "            hidden6,\n",
    "            hidden7,\n",
    "            hidden8\n",
    "        )\n",
    "        self._classifier = nn.Sequential(\n",
    "            hidden9,\n",
    "            hidden10\n",
    "        )\n",
    "        self._digit_length = nn.Sequential(nn.Linear(3072, 7))\n",
    "        self._digit1 = nn.Sequential(nn.Linear(3072, 11))\n",
    "        self._digit2 = nn.Sequential(nn.Linear(3072, 11))\n",
    "        self._digit3 = nn.Sequential(nn.Linear(3072, 11))\n",
    "        self._digit4 = nn.Sequential(nn.Linear(3072, 11))\n",
    "        self._digit5 = nn.Sequential(nn.Linear(3072, 11))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._features(x)\n",
    "        x = x.view(x.size(0), 192 * 7 * 7)\n",
    "        x = self._classifier(x)\n",
    "\n",
    "        length_logits, digits_logits = self._digit_length(x), [self._digit1(x),\n",
    "                                                               self._digit2(x),\n",
    "                                                               self._digit3(x),\n",
    "                                                               self._digit4(x),\n",
    "                                                               self._digit5(x)]\n",
    "        return length_logits, digits_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "###### process_image Function gets the image at a particular idx ######\n",
    "#######################################################################\n",
    "\n",
    "\n",
    "def process_image(csvfile, idx):\n",
    "    df = pd.read_csv(csvfile)\n",
    "    img_name = os.path.join(os.path.split(os.getcwd())[0], 'data', df['filename'][idx].replace(\"/\", \"\\\\\"))\n",
    "    image = Image.open(img_name) #image=Image.open(img_name)\n",
    "        \n",
    "    height=[]\n",
    "    width=[]\n",
    "    top=[]\n",
    "    left=[]\n",
    "\n",
    "    for i in range(5):\n",
    "        bb = df['bbox%d'%(i+1)][idx]\n",
    "        bb = bb[1:(len(bb)-1)]\n",
    "        bb = bb.split(',')\n",
    "        bb = [float(element) for element in bb]\n",
    "        height.append(bb[3])\n",
    "        width.append(bb[2])\n",
    "        top.append(bb[1])\n",
    "        left.append(bb[0])\n",
    "            \n",
    "    new_left = [ii for ii in left if ii != 0]\n",
    "    new_top = [ii for ii in top if ii != 0]\n",
    "        \n",
    "    if new_left==[]:\n",
    "        new_left.append(0)\n",
    "        \n",
    "    if new_top==[]:\n",
    "        new_top.append(0)\n",
    "            \n",
    "    _left = int(min(new_left))\n",
    "    upper = int(min(new_top))\n",
    "    right = int(max(left)) + int(max(width))\n",
    "    lower = int(max(top)) + int(max(height))\n",
    "       \n",
    "    _image = image.crop(box=(_left, upper, right, lower))\n",
    "    \n",
    "    labels=[]\n",
    "    labels.append(int(df['len'][idx]))\n",
    "        \n",
    "    for i in range(5):\n",
    "        num = df.iloc[idx]['num%d'%(i+1)]\n",
    "        labels.append(int(num)+1)\n",
    "    \n",
    "    #resize and convert to np array\n",
    "    _image = _image.resize([64,64])\n",
    "    image_array = np.array(_image)\n",
    "    #_image = image_array.reshape([64, 64, 3])\n",
    "    image_array = Image.fromarray(image_array) #image_array = np.array(_image)\n",
    "    labels_array = np.array(labels)\n",
    "    labels_array = torch.from_numpy(labels_array).long()\n",
    "        \n",
    "    return image_array, labels_array\n",
    "\n",
    "def load_model():\n",
    "    classifier = torch.load('SVHN_model_checkpoint.tar', map_location=torch.device(device))\n",
    "    model = Model()\n",
    "    model.load_state_dict(classifier['model_state_dict'])\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Prediction accuracy is:  100.0 %\n",
      "Predicted Labels are:  [1, 0, 2]\n",
      "Predicted Length is:  3\n",
      "--------------------------------------------------\n",
      "Actual Labels are:  [1, 0, 2]\n",
      "Actual Length is:  3\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###########################\n",
    "####### Inference #########\n",
    "###########################\n",
    "\n",
    "classifier = torch.load('SVHN_model_checkpoint.tar', map_location=device)\n",
    "inf_model = Model()\n",
    "inf_model.load_state_dict(classifier['model_state_dict'])\n",
    "inf_model.eval()\n",
    "\n",
    "#prediction idx here\n",
    "idx = 4794\n",
    "image, labels = process_image('test.csv', idx)\n",
    "plt.imshow(image)\n",
    "t_image = test_transforms(image).view(1, 3, 64, 64)\n",
    "\n",
    "\n",
    "length_logits, digits_logits = inf_model(t_image)\n",
    "\n",
    "_, length_top_class = length_logits.topk(1, dim=1)\n",
    "                    \n",
    "digits_top_class = []\n",
    "                    \n",
    "for i in range(5):\n",
    "    _, _digits_top_class = digits_logits[i].topk(1, dim=1)\n",
    "    digits_top_class.append(_digits_top_class)\n",
    "    \n",
    "accuracy = 0\n",
    "equals = length_top_class == labels[0].view(*length_top_class.shape)\n",
    "accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "                    \n",
    "for i in range(5):\n",
    "    equals = digits_top_class[i] == labels[i+1]\n",
    "    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "    \n",
    "    \n",
    "digits_logits\n",
    "print(\"-\"*50)\n",
    "print(\"Prediction accuracy is: \", (accuracy/6)*100, \"%\")\n",
    "print(\"Predicted Labels are: \",[(i.item()-1) for i in digits_top_class if i!= 0])\n",
    "print(\"Predicted Length is: \", length_top_class.item())\n",
    "print(\"-\"*50)\n",
    "print(\"Actual Labels are: \",[(i.item()-1) for i in labels.data[1:] if i!= 0])\n",
    "print(\"Actual Length is: \",labels[0].item())\n",
    "print(\"-\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
